"""make_extraction_document_id_nullable

Revision ID: 0e0fe1243464
Revises: e5f6a7b8c9d0
Create Date: 2025-12-10 03:22:22.249991

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '0e0fe1243464'
down_revision = 'e5f6a7b8c9d0'
branch_labels = None
depends_on = None


def upgrade() -> None:
# ### commands auto generated by Alembic - please adjust! ###
    # Make operations defensive - only drop if they exist
    try:
        op.drop_index(op.f('idx_chat_sessions_collection_id'), table_name='chat_sessions')
    except:
        pass
    try:
        op.drop_constraint(op.f('chat_sessions_collection_id_fkey'), 'chat_sessions', type_='foreignkey')
    except:
        pass
    try:
        op.drop_column('chat_sessions', 'collection_id')
    except:
        pass
    try:
        op.drop_index(op.f('idx_document_chunks_metadata_chunk_sequence'), table_name='document_chunks', postgresql_where="((chunk_metadata ->> 'chunk_sequence'::text) IS NOT NULL)")
    except:
        pass
    try:
        op.drop_index(op.f('idx_document_chunks_metadata_is_continuation'), table_name='document_chunks', postgresql_where="((chunk_metadata ->> 'is_continuation'::text) IS NOT NULL)")
    except:
        pass
    try:
        op.drop_index(op.f('idx_document_chunks_metadata_parent_chunk_id'), table_name='document_chunks', postgresql_where="((chunk_metadata ->> 'parent_chunk_id'::text) IS NOT NULL)")
    except:
        pass
    try:
        op.drop_index(op.f('idx_document_chunks_metadata_section_id'), table_name='document_chunks', postgresql_where="((chunk_metadata ->> 'section_id'::text) IS NOT NULL)")
    except:
        pass
    op.alter_column('extractions', 'document_id',
               existing_type=sa.VARCHAR(length=36),
               nullable=True)
    op.alter_column('extractions', 'status',
               existing_type=sa.VARCHAR(length=20),
               server_default=None,
               existing_nullable=False)
    try:
        op.drop_constraint(op.f('extractions_document_id_fkey'), 'extractions', type_='foreignkey')
    except:
        pass
    op.create_foreign_key(None, 'extractions', 'documents', ['document_id'], ['id'], ondelete='SET NULL')
    op.alter_column('session_documents', 'added_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=True,
               existing_server_default=sa.text('now()'))
    try:
        op.drop_constraint(op.f('uq_session_documents_session_document'), 'session_documents', type_='unique')
    except:
        pass
    op.alter_column('usage_logs', 'is_deleted',
               existing_type=sa.BOOLEAN(),
               server_default=None,
               existing_nullable=False)
    # Removed foreign key constraint - usage_logs should preserve historical records
    # op.drop_constraint(op.f('usage_logs_extraction_id_fkey'), 'usage_logs', type_='foreignkey')
    op.alter_column('workflow_runs', 'mode',
               existing_type=sa.VARCHAR(length=30),
               server_default=None,
               existing_nullable=False)
    op.alter_column('workflow_runs', 'status',
               existing_type=sa.VARCHAR(length=20),
               server_default=None,
               existing_nullable=False)
    op.alter_column('workflow_runs', 'version',
               existing_type=sa.INTEGER(),
               server_default=None,
               existing_nullable=False)
    try:
        op.drop_index(op.f('idx_workflow_runs_snapshot'), table_name='workflow_runs', postgresql_using='gin')
    except:
        pass
    try:
        op.drop_constraint(op.f('workflow_runs_workflow_id_fkey'), 'workflow_runs', type_='foreignkey')
    except:
        pass
    op.create_foreign_key(None, 'workflow_runs', 'workflows', ['workflow_id'], ['id'], ondelete='SET NULL')
    op.alter_column('workflows', 'domain',
               existing_type=sa.VARCHAR(length=50),
               server_default=None,
               existing_nullable=False)
    op.alter_column('workflows', 'output_format',
               existing_type=sa.VARCHAR(length=50),
               server_default=None,
               existing_nullable=False)
    op.alter_column('workflows', 'min_documents',
               existing_type=sa.INTEGER(),
               server_default=None,
               existing_nullable=False)
    op.alter_column('workflows', 'version',
               existing_type=sa.INTEGER(),
               server_default=None,
               existing_nullable=False)
    op.alter_column('workflows', 'active',
               existing_type=sa.BOOLEAN(),
               server_default=None,
               existing_nullable=False)
    try:
        op.drop_index(op.f('idx_workflows_retrieval_spec'), table_name='workflows', postgresql_using='gin')
    except:
        pass
    # ### end Alembic commands ###


def downgrade() -> None:
# ### commands auto generated by Alembic - please adjust! ###
    op.create_index(op.f('idx_workflows_retrieval_spec'), 'workflows', ['retrieval_spec_json'], unique=False, postgresql_using='gin')
    op.alter_column('workflows', 'active',
               existing_type=sa.BOOLEAN(),
               server_default=sa.text('true'),
               existing_nullable=False)
    op.alter_column('workflows', 'version',
               existing_type=sa.INTEGER(),
               server_default=sa.text('1'),
               existing_nullable=False)
    op.alter_column('workflows', 'min_documents',
               existing_type=sa.INTEGER(),
               server_default=sa.text('1'),
               existing_nullable=False)
    op.alter_column('workflows', 'output_format',
               existing_type=sa.VARCHAR(length=50),
               server_default=sa.text("'markdown'::character varying"),
               existing_nullable=False)
    op.alter_column('workflows', 'domain',
               existing_type=sa.VARCHAR(length=50),
               server_default=sa.text("'private_equity'::character varying"),
               existing_nullable=False)
    op.drop_constraint(None, 'workflow_runs', type_='foreignkey')
    op.create_foreign_key(op.f('workflow_runs_workflow_id_fkey'), 'workflow_runs', 'workflows', ['workflow_id'], ['id'], ondelete='CASCADE')
    op.create_index(op.f('idx_workflow_runs_snapshot'), 'workflow_runs', ['workflow_snapshot'], unique=False, postgresql_using='gin')
    op.alter_column('workflow_runs', 'version',
               existing_type=sa.INTEGER(),
               server_default=sa.text('1'),
               existing_nullable=False)
    op.alter_column('workflow_runs', 'status',
               existing_type=sa.VARCHAR(length=20),
               server_default=sa.text("'queued'::character varying"),
               existing_nullable=False)
    op.alter_column('workflow_runs', 'mode',
               existing_type=sa.VARCHAR(length=30),
               server_default=sa.text("'single_doc'::character varying"),
               existing_nullable=False)
    # Removed foreign key constraint - usage_logs should preserve historical records
    # op.create_foreign_key(op.f('usage_logs_extraction_id_fkey'), 'usage_logs', 'extractions', ['extraction_id'], ['id'])
    op.alter_column('usage_logs', 'is_deleted',
               existing_type=sa.BOOLEAN(),
               server_default=sa.text('false'),
               existing_nullable=False)
    op.create_unique_constraint(op.f('uq_session_documents_session_document'), 'session_documents', ['session_id', 'document_id'])
    op.alter_column('session_documents', 'added_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               nullable=False,
               existing_server_default=sa.text('now()'))
    op.drop_constraint(None, 'extractions', type_='foreignkey')
    op.create_foreign_key(op.f('extractions_document_id_fkey'), 'extractions', 'documents', ['document_id'], ['id'], ondelete='CASCADE')
    op.alter_column('extractions', 'status',
               existing_type=sa.VARCHAR(length=20),
               server_default=sa.text("'processing'::character varying"),
               existing_nullable=False)
    op.alter_column('extractions', 'document_id',
               existing_type=sa.VARCHAR(length=36),
               nullable=False)
    op.create_index(op.f('idx_document_chunks_metadata_section_id'), 'document_chunks', [sa.literal_column("(chunk_metadata ->> 'section_id'::text)")], unique=False, postgresql_where="((chunk_metadata ->> 'section_id'::text) IS NOT NULL)")
    op.create_index(op.f('idx_document_chunks_metadata_parent_chunk_id'), 'document_chunks', [sa.literal_column("(chunk_metadata ->> 'parent_chunk_id'::text)")], unique=False, postgresql_where="((chunk_metadata ->> 'parent_chunk_id'::text) IS NOT NULL)")
    op.create_index(op.f('idx_document_chunks_metadata_is_continuation'), 'document_chunks', [sa.literal_column("(chunk_metadata ->> 'is_continuation'::text)")], unique=False, postgresql_where="((chunk_metadata ->> 'is_continuation'::text) IS NOT NULL)")
    op.create_index(op.f('idx_document_chunks_metadata_chunk_sequence'), 'document_chunks', [sa.literal_column("((chunk_metadata ->> 'chunk_sequence'::text)::integer)")], unique=False, postgresql_where="((chunk_metadata ->> 'chunk_sequence'::text) IS NOT NULL)")
    op.add_column('chat_sessions', sa.Column('collection_id', sa.VARCHAR(length=36), autoincrement=False, nullable=True))
    op.create_foreign_key(op.f('chat_sessions_collection_id_fkey'), 'chat_sessions', 'collections', ['collection_id'], ['id'], ondelete='CASCADE')
    op.create_index(op.f('idx_chat_sessions_collection_id'), 'chat_sessions', ['collection_id'], unique=False)
    # ### end Alembic commands ###